---
title: "Projects"
layout: default
permalink: /projects/
---

  <div class="two-column-layout" style="display: flex; margin-top: 50px; justify-content: space-between;">
        <div class="text-column" style="flex: 1; justify-contect; margin-right: 50px;">
            <h3 style="font-weight: bold;">
            <a href="/probe/" 
              style="text-decoration: none; color: #B7D8FA; transition: color 0.2s ease;"
              onmouseover="this.style.color='#5555FA';" 
              onmouseout="this.style.color='#B7D8FA';">
              Computer Assisted Nueral Probe Insertion ðŸ”—
            </a>
            </h3>
            <ul style="list-style-type: disc; margin-left: -20px; font-size: 0.9em;">
                <li>Developed a computer-vision pipeline to detect the probe shaft and tip, classify bending, and enable real-time feedback during insertion.</li>
                <li>Curated and labeled datasets, trained segmentation and ResNet models, and analyzed performance issues such as dataset imbalance and visibility challenges.</li>
                <li>Designed and implemented a 3D calibration system using ArUco markers and camera parameters to convert 2D detections into accurate 3D insertion coordinates.</li>
                <li>Built the workflow for automated probe insertion, including insertion-point estimation, reference-frame creation, trajectory planning for robotic control./li>
            </ul>
        </div>
        <div class="video-column" style="flex: 1; margin-top: 30px">
            <a href="/probe/">
                <img src= https://github.com/user-attachments/assets/07e8e5ef-b80e-49d2-8773-8c01d5438507 alt="Video Thumbnail" style="width: 100%; cursor: pointer;">
            </a>
        </div>
</div>

---






















  <div class="two-column-layout" style="display: flex; margin-top: 50px; justify-content: space-between;">
        <div class="text-column" style="flex: 1; justify-contect; margin-right: 50px;">
            <h3 style="font-weight: bold;">
            <a href="https://github.com/shizratariq/Turtlebot3-RRT-Pathfinder" 
              style="text-decoration: none; color: #B7D8FA; transition: color 0.2s ease;"
              onmouseover="this.style.color='#5555FA';" 
              onmouseout="this.style.color='#B7D8FA';">
              Turtlebot3 RRT Pathfinder ðŸ”—
            </a>
            </h3>
            <ul style="list-style-type: disc; margin-left: -20px; font-size: 0.9em;">
                <li>Developed and implemented the Rapidly-Exploring Random Tree (RRT) algorithm for autonomous maze navigation in Gazebo simulations.</li>
                <li>Optimized motor command accuracy to enhance path-following precision.</li>
                <li>Addressed Lidar inconsistencies by refining sensor data processing for improved obstacle detection.</li>
                <li>Achieved a 40% success rate in maze traversal under simulated conditions.</li>
                <li>Recorded a fastest traversal time of 1 minute and 42 seconds.</li>
                <li>Improved overall navigation efficiency through iterative testing and parameter tuning. </li>
            </ul>
        </div>
        <div class="video-column" style="flex: 1; margin-top: 30px">
            <a href="https://github.com/shizratariq/Turtlebot3-RRT-Pathfinder" target="_blank">
                <img src= https://github.com/user-attachments/assets/a241002d-1e30-4e9d-ac42-8e8d7268ba81 alt="Video Thumbnail" style="width: 100%; cursor: pointer;">
            </a>
        </div>
</div>

---

  <div class="two-column-layout" style="display: flex; margin-top: 50px; justify-content: space-between;">
        <div class="text-column" style="flex: 1; justify-contect; margin-right: 50px;">
            <h3 style="font-weight: bold;">
            <a href="/super_resol/" 
              style="text-decoration: none; color: #B7D8FA; transition: color 0.2s ease;"
              onmouseover="this.style.color='#5555FA';" 
              onmouseout="this.style.color='#B7D8FA';">
              SuperResolution and Object Detection on Remote Sensing Imagery ðŸ”—
            </a>
            </h3>
            <ul style="list-style-type: disc; margin-left: -20px; font-size: 0.9em;">
                <li>Implemented <strong>SRGAN (4x super-resolution)</strong> to enhance image quality.</li>
                <li>Improved <strong>Peak Signal-to-Noise Ratio (PSNR)</strong> and <strong>Structural Similarity Index (SSIM)</strong> metrics.</li>
                <li>Achieved a <strong>+18.7% increase in mean Average Precision (mAP)</strong> for aerial object detection.</li>
                <li>Boosted mAP from <strong>49.6% to 68.3%</strong> using enhanced images.</li>
                <li>Utilized <strong>YOLOv11-OBB</strong> for detecting <strong>8 object classes</strong> in the <strong>DOTA dataset</strong>.</li>
                <li>Enhanced object detection accuracy by improving input image resolution.</li>
        </div>
        <div class="video-column" style="flex: 1; margin-top: 30px">
            <a href="/super_resol/" target="_blank">
                <img src= https://github.com/user-attachments/assets/cfb2e808-574e-4ed2-8ac2-62b2c98a1d27 alt="Video Thumbnail" style="width: 100%; cursor: pointer;">
            </a>
        </div>
</div>

---

  <div class="two-column-layout" style="display: flex; margin-top: 50px; justify-content: space-between;">
        <div class="text-column" style="flex: 1; justify-contect; margin-right: 50px;">
            <h3 style="font-weight: bold;">
            <a href="/auto/" 
              style="text-decoration: none; color: #B7D8FA; transition: color 0.2s ease;"
              onmouseover="this.style.color='#5555FA';" 
              onmouseout="this.style.color='#B7D8FA';">
              Autoethnographic Study on Social Media Usage ðŸ”—
            </a>
            </h3>
            <ul style="list-style-type: disc; margin-left: -20px; font-size: 0.9em;">
                <li>Collected two weeks of data on my social media use through field notes, journal entries, and reflections.</li>
                <li>Examined how my cultural background and personal habits shape the way I use different social apps.</li>
                <li>Identified key themes such as emotional impact, productivity vs. distraction, and platform-specific behaviors.</li>
                <li>Connected my experiences to existing research and reflected on how social media influences my daily life and wellbeing.</li>
            </ul>
        </div>
        <div class="video-column" style="flex: 1; margin-top: 30px">
            <a href="/auto/" target="_blank">
                <img src= https://github.com/user-attachments/assets/d391b6c6-737d-4968-81ec-1e57733d8a47 alt="Video Thumbnail" style="width: 100%; cursor: pointer;">
            </a>
        </div>
</div>
              
---
  <div class="two-column-layout" style="display: flex; margin-top: 50px; justify-content: space-between;">
        <div class="text-column" style="flex: 1; justify-contect; margin-right: 50px;">
            <h3 style="font-weight: bold;">
            <a href="/breast_cancer/" 
              style="text-decoration: none; color: #B7D8FA; transition: color 0.2s ease;"
              onmouseover="this.style.color='#5555FA';" 
              onmouseout="this.style.color='#B7D8FA';">
              Breast Cancer Detection ðŸ”—
            </a>
            </h3>
            <ul style="list-style-type: disc; margin-left: -20px; font-size: 0.9em;">
                <li>Developed a mammography-based breast cancer detection system utilizing multiple machine learning techniques.</li>
                <li>Implemented Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Logistic Regression, Neural Networks, and XGBoost for classification.</li>
                <li>achieved 96.49% accuracy, 100% precision, 92.86% recall, 95.12% F1-score, and 0.996 AUC.</li>
        </div>
        <div class="video-column" style="flex: 1; margin-top: 30px">
            <a href="/breast_cancer/"  target="_blank">
                <img src= https://github.com/user-attachments/assets/965ce6ab-afae-48f5-917c-4b4acd009897 alt="Video Thumbnail" style="width: 100%; cursor: pointer;">
            </a>
        </div>
</div>
              
---

  <div class="two-column-layout" style="display: flex; margin-top: 50px; justify-content: space-between;">
        <div class="text-column" style="flex: 1; justify-contect; margin-right: 50px;">
            <h3 style="font-weight: bold;">
            <a href="/subtitle/" 
              style="text-decoration: none; color: #B7D8FA; transition: color 0.2s ease;"
              onmouseover="this.style.color='#5555FA';" 
              onmouseout="this.style.color='#B7D8FA';">
              Accurate Subtitle Generation in Videos ðŸ”—
            </a>
            </h3>
            <ul style="list-style-type: disc; margin-left: -20px; font-size: 0.9em;">
                <li>Developed a system to enhance subtitle accuracy in videos by improving transcription quality, segmentation, and timestamp alignment.</li>
                <li>Evaluated Whisper variants, LLM-based segmentation (Gemini, SaT), and a custom segmentation function to optimize readability and synchronization.</li>
                <li>Built a custom dataset with refined SRT files and fine-tuned STT models to better handle accents, long speech, and noisy environments.</li>
                <li>Implemented a full end-to-end Streamlit pipeline for generating improved subtitles, integrating Whisper transcription, segmentation methods, and FFmpeg-based SRT embedding.</li>
        </div>
        <div class="video-column" style="flex: 1; margin-top: 30px">
            <a href="/subtitle/" target="_blank">
                <img src= https://github.com/user-attachments/assets/1f43871e-df3a-4946-a2b9-22edc3fd0c6c alt="Video Thumbnail" style="width: 100%; cursor: pointer;">
            </a>
        </div>
</div>


