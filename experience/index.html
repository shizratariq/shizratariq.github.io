<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Experience | Shizra Tariq</title>
<meta name="keywords" content="">
<meta name="description" content="Research Assistant Biosensing and Biorobotics Laboratory, University of Minnesota — Summer 2025–Present
I am developing a real-time computer vision and robotics pipeline for automated probe insertion in the mouse brain to monitor neural activity. My work integrates object detection with keypoint-based pose estimation and Perspective-n-Point (PnP) to recover the full 6-DoF probe pose, while employing CNN-based classification to assess probe bending and stability under challenging visual conditions. Teaching Assistant Carlson School of Management, University of Minnesota — Summer 2025">
<meta name="author" content="Shizra Tariq">
<link rel="canonical" href="https://shizratariq.github.io/experience/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.319c3c1fd58ba2da1d33ada5234cc7970adf6d05d595ba115d5f87db16905004.css" integrity="sha256-MZw8H9WLotodM62lI0zHlwrfbQXVlboRXV&#43;H2xaQUAQ=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://shizratariq.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://shizratariq.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://shizratariq.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://shizratariq.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://shizratariq.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Experience" />
<meta property="og:description" content="Research Assistant Biosensing and Biorobotics Laboratory, University of Minnesota — Summer 2025–Present
I am developing a real-time computer vision and robotics pipeline for automated probe insertion in the mouse brain to monitor neural activity. My work integrates object detection with keypoint-based pose estimation and Perspective-n-Point (PnP) to recover the full 6-DoF probe pose, while employing CNN-based classification to assess probe bending and stability under challenging visual conditions. Teaching Assistant Carlson School of Management, University of Minnesota — Summer 2025" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://shizratariq.github.io/experience/" /><meta property="article:section" content="" />



<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Experience"/>
<meta name="twitter:description" content="Research Assistant Biosensing and Biorobotics Laboratory, University of Minnesota — Summer 2025–Present
I am developing a real-time computer vision and robotics pipeline for automated probe insertion in the mouse brain to monitor neural activity. My work integrates object detection with keypoint-based pose estimation and Perspective-n-Point (PnP) to recover the full 6-DoF probe pose, while employing CNN-based classification to assess probe bending and stability under challenging visual conditions. Teaching Assistant Carlson School of Management, University of Minnesota — Summer 2025"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Experience",
      "item": "https://shizratariq.github.io/experience/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Experience",
  "name": "Experience",
  "description": "Research Assistant Biosensing and Biorobotics Laboratory, University of Minnesota — Summer 2025–Present\nI am developing a real-time computer vision and robotics pipeline for automated probe insertion in the mouse brain to monitor neural activity. My work integrates object detection with keypoint-based pose estimation and Perspective-n-Point (PnP) to recover the full 6-DoF probe pose, while employing CNN-based classification to assess probe bending and stability under challenging visual conditions. Teaching Assistant Carlson School of Management, University of Minnesota — Summer 2025",
  "keywords": [
    
  ],
  "articleBody": "Research Assistant Biosensing and Biorobotics Laboratory, University of Minnesota — Summer 2025–Present\nI am developing a real-time computer vision and robotics pipeline for automated probe insertion in the mouse brain to monitor neural activity. My work integrates object detection with keypoint-based pose estimation and Perspective-n-Point (PnP) to recover the full 6-DoF probe pose, while employing CNN-based classification to assess probe bending and stability under challenging visual conditions. Teaching Assistant Carlson School of Management, University of Minnesota — Summer 2025\nAssisted students in MSF 6921: Introduction to Python with hands-on coding exercises, clarifying core Python concepts and the use of data analysis libraries Supported the instructor by grading assignments and providing guidance during class and office hours Research Assistant College of Science and Engineering, University of Minnesota\nCollaborated on robotic surgery for histotripsy using the UR5e robotic arm with ROS2 and MoveIt2 Mapped singular configurations in C-space to improve motion planning Developed path-planning algorithms for constrained and unconstrained trajectories, ensuring collision avoidance in an aquatic environment Technical Project Manager Quantum-h, UK\nLed Cross-Functional Agile (CSA) team for international development, QA, and project management Engineered scalable database architectures, optimizing data retrieval speed by 30% Fine-tuned complex queries, ensuring complete data accuracy and high integrity across all datasets Research Assistant Abel \u0026 Mercer Co., UK\nProposed and implemented AI solutions that improved customer interaction metrics by 20% Designed and trained deep learning models for image recognition and segmentation using TensorFlow and PyTorch Optimized real-time image processing and model inference with NumPy, enhancing virtual try-on tool responsiveness by 20% Machine Learning Intern Advance Automation \u0026 Robotics Lab (ARAL), Pakistan\nContributed to the Prosthetic Arm project by implementing SVM classification using MATLAB and Python Processed muscle signal data using FMG sensors for motion intent recognition Utilized scikit-learn, pandas, and TensorFlow for data analysis and predictive modeling Artificial Intelligence Intern OPENAIMP, United States\nEngineered and deployed AI chatbots using RASA for enhanced user engagement Designed 15 distinct conversational flows, improving interaction efficiency Reduced average response time per inquiry by over 10 seconds through optimized NLP models ",
  "wordCount" : "340",
  "inLanguage": "en",
  "datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Shizra Tariq"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://shizratariq.github.io/experience/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Shizra Tariq",
    "logo": {
      "@type": "ImageObject",
      "url": "https://shizratariq.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://shizratariq.github.io/" accesskey="h" title="Shizra Tariq (Alt + H)">Shizra Tariq</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://shizratariq.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://shizratariq.github.io/experience/" title="Experience">
                    <span class="active">Experience</span>
                </a>
            </li>
            <li>
                <a href="https://shizratariq.github.io/projects/" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="https://shizratariq.github.io/skills/" title="Skills">
                    <span>Skills</span>
                </a>
            </li>
            <li>
                <a href="https://shizratariq.github.io/awards/" title="Awards">
                    <span>Awards</span>
                </a>
            </li>
            <li>
                <a href="https://shizratariq.github.io/extracurricular/" title="Extracurricular">
                    <span>Extracurricular</span>
                </a>
            </li>
            <li>
                <a href="https://shizratariq.github.io/cv/" title="CV">
                    <span>CV</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Experience
    </h1>
    <div class="post-meta">2 min&nbsp;·&nbsp;Shizra Tariq

</div>
  </header> 
  <div class="post-content"><h2 id="h2research-assistanth2"><h2>Research Assistant</h2><a hidden class="anchor" aria-hidden="true" href="#h2research-assistanth2">#</a></h2>
<p><span style="font-size: 0.85em; margin-bottom: 10px; display: inline-block;"><em>Biosensing and Biorobotics Laboratory, University of Minnesota — Summer 2025–Present</em></span></p>
<ul>
<li>I am developing a real-time computer vision and robotics pipeline for automated probe insertion in the mouse brain to monitor neural activity. My work integrates object detection with keypoint-based pose estimation and Perspective-n-Point (PnP) to recover the full 6-DoF probe pose, while employing CNN-based classification to assess probe bending and stability under challenging visual conditions.</li>
</ul>
<hr>
<h2 id="h2teaching-assistanth2"><h2>Teaching Assistant</h2><a hidden class="anchor" aria-hidden="true" href="#h2teaching-assistanth2">#</a></h2>
<p><span style="font-size: 0.85em; margin-bottom: 10px; display: inline-block;"><em>Carlson School of Management, University of Minnesota — Summer 2025</em></span></p>
<ul>
<li>Assisted students in MSF 6921: Introduction to Python with hands-on coding exercises, clarifying core Python concepts and the use of data analysis libraries</li>
<li>Supported the instructor by grading assignments and providing guidance during class and office hours</li>
</ul>
<hr>
<h2 id="h2research-assistant-h2"><h2>Research Assistant </h2><a hidden class="anchor" aria-hidden="true" href="#h2research-assistant-h2">#</a></h2>
<p><span style="font-size: 0.85em; margin-bottom: 10px; display: inline-block;"><em>College of Science and Engineering, University of Minnesota</em></span></p>
<ul>
<li>Collaborated on robotic surgery for histotripsy using the UR5e robotic arm with ROS2 and MoveIt2</li>
<li>Mapped singular configurations in C-space to improve motion planning</li>
<li>Developed path-planning algorithms for constrained and unconstrained trajectories, ensuring collision avoidance in an aquatic environment</li>
</ul>
<hr>
<h2 id="h2technical-project-manager-h2"><h2>Technical Project Manager </h2><a hidden class="anchor" aria-hidden="true" href="#h2technical-project-manager-h2">#</a></h2>
<p><span style="font-size: 0.85em; margin-bottom: 10px; display: inline-block;"><em>Quantum-h, UK</em></span></p>
<ul>
<li>Led Cross-Functional Agile (CSA) team for international development, QA, and project management</li>
<li>Engineered scalable database architectures, optimizing data retrieval speed by 30%</li>
<li>Fine-tuned complex queries, ensuring complete data accuracy and high integrity across all datasets</li>
</ul>
<hr>
<h2 id="h2research-assistant-h2-1"><h2>Research Assistant </h2><a hidden class="anchor" aria-hidden="true" href="#h2research-assistant-h2-1">#</a></h2>
<p><span style="font-size: 0.85em; margin-bottom: 10px; display: inline-block;"><em>Abel &amp; Mercer Co., UK</em></span></p>
<ul>
<li>Proposed and implemented AI solutions that improved customer interaction metrics by 20%</li>
<li>Designed and trained deep learning models for image recognition and segmentation using TensorFlow and PyTorch</li>
<li>Optimized real-time image processing and model inference with NumPy, enhancing virtual try-on tool responsiveness by 20%</li>
</ul>
<hr>
<h2 id="h2-machine-learning-intern-h2"><h2> Machine Learning Intern </h2><a hidden class="anchor" aria-hidden="true" href="#h2-machine-learning-intern-h2">#</a></h2>
<p><span style="font-size: 0.85em; margin-bottom: 10px; display: inline-block;"><em>Advance Automation &amp; Robotics Lab (ARAL), Pakistan</em></span></p>
<ul>
<li>Contributed to the Prosthetic Arm project by implementing SVM classification using MATLAB and Python</li>
<li>Processed muscle signal data using FMG sensors for motion intent recognition</li>
<li>Utilized scikit-learn, pandas, and TensorFlow for data analysis and predictive modeling</li>
</ul>
<hr>
<h2 id="h2artificial-intelligence-intern-h2"><h2>Artificial Intelligence Intern </h2><a hidden class="anchor" aria-hidden="true" href="#h2artificial-intelligence-intern-h2">#</a></h2>
<p><span style="font-size: 0.85em; margin-bottom: 10px; display: inline-block;"><em>OPENAIMP, United States</em></span></p>
<ul>
<li>Engineered and deployed AI chatbots using RASA for enhanced user engagement</li>
<li>Designed 15 distinct conversational flows, improving interaction efficiency</li>
<li>Reduced average response time per inquiry by over 10 seconds through optimized NLP models</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://shizratariq.github.io/">Shizra Tariq</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
