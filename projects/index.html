<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Projects | Shizra Tariq</title>
<meta name="keywords" content="">
<meta name="description" content="Computer Assisted Nueral Probe Insertion ðŸ”— Developed a computer-vision pipeline to detect the probe shaft and tip, classify bending, and enable real-time feedback during insertion. Curated and labeled datasets, trained segmentation and ResNet models, and analyzed performance issues such as dataset imbalance and visibility challenges. Designed and implemented a 3D calibration system using ArUco markers and camera parameters to convert 2D detections into accurate 3D insertion coordinates. Built the workflow for automated probe insertion, including insertion-point estimation, reference-frame creation, trajectory planning for robotic control.">
<meta name="author" content="Shizra Tariq">
<link rel="canonical" href="https://shizratariq.github.io/projects/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.319c3c1fd58ba2da1d33ada5234cc7970adf6d05d595ba115d5f87db16905004.css" integrity="sha256-MZw8H9WLotodM62lI0zHlwrfbQXVlboRXV&#43;H2xaQUAQ=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://shizratariq.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://shizratariq.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://shizratariq.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://shizratariq.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://shizratariq.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Projects" />
<meta property="og:description" content="Computer Assisted Nueral Probe Insertion ðŸ”— Developed a computer-vision pipeline to detect the probe shaft and tip, classify bending, and enable real-time feedback during insertion. Curated and labeled datasets, trained segmentation and ResNet models, and analyzed performance issues such as dataset imbalance and visibility challenges. Designed and implemented a 3D calibration system using ArUco markers and camera parameters to convert 2D detections into accurate 3D insertion coordinates. Built the workflow for automated probe insertion, including insertion-point estimation, reference-frame creation, trajectory planning for robotic control." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://shizratariq.github.io/projects/" /><meta property="article:section" content="" />



<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Projects"/>
<meta name="twitter:description" content="Computer Assisted Nueral Probe Insertion ðŸ”— Developed a computer-vision pipeline to detect the probe shaft and tip, classify bending, and enable real-time feedback during insertion. Curated and labeled datasets, trained segmentation and ResNet models, and analyzed performance issues such as dataset imbalance and visibility challenges. Designed and implemented a 3D calibration system using ArUco markers and camera parameters to convert 2D detections into accurate 3D insertion coordinates. Built the workflow for automated probe insertion, including insertion-point estimation, reference-frame creation, trajectory planning for robotic control."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Projects",
      "item": "https://shizratariq.github.io/projects/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Projects",
  "name": "Projects",
  "description": "Computer Assisted Nueral Probe Insertion ðŸ”— Developed a computer-vision pipeline to detect the probe shaft and tip, classify bending, and enable real-time feedback during insertion. Curated and labeled datasets, trained segmentation and ResNet models, and analyzed performance issues such as dataset imbalance and visibility challenges. Designed and implemented a 3D calibration system using ArUco markers and camera parameters to convert 2D detections into accurate 3D insertion coordinates. Built the workflow for automated probe insertion, including insertion-point estimation, reference-frame creation, trajectory planning for robotic control.",
  "keywords": [
    
  ],
  "articleBody": " Computer Assisted Nueral Probe Insertion ðŸ”— Developed a computer-vision pipeline to detect the probe shaft and tip, classify bending, and enable real-time feedback during insertion. Curated and labeled datasets, trained segmentation and ResNet models, and analyzed performance issues such as dataset imbalance and visibility challenges. Designed and implemented a 3D calibration system using ArUco markers and camera parameters to convert 2D detections into accurate 3D insertion coordinates. Built the workflow for automated probe insertion, including insertion-point estimation, reference-frame creation, trajectory planning for robotic control./li\u003e Turtlebot3 RRT Pathfinder ðŸ”— Developed and implemented the Rapidly-Exploring Random Tree (RRT) algorithm for autonomous maze navigation in Gazebo simulations. Optimized motor command accuracy to enhance path-following precision. Addressed Lidar inconsistencies by refining sensor data processing for improved obstacle detection. Achieved a 40% success rate in maze traversal under simulated conditions. Recorded a fastest traversal time of 1 minute and 42 seconds. Improved overall navigation efficiency through iterative testing and parameter tuning. SuperResolution and Object Detection on Remote Sensing Imagery ðŸ”— Implemented SRGAN (4x super-resolution) to enhance image quality. Improved Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) metrics. Achieved a +18.7% increase in mean Average Precision (mAP) for aerial object detection. Boosted mAP from 49.6% to 68.3% using enhanced images. Utilized YOLOv11-OBB for detecting 8 object classes in the DOTA dataset. Enhanced object detection accuracy by improving input image resolution. Autoethnographic Study on Social Media Usage ðŸ”— Collected two weeks of data on my social media use through field notes, journal entries, and reflections. Examined how my cultural background and personal habits shape the way I use different social apps. Identified key themes such as emotional impact, productivity vs. distraction, and platform-specific behaviors. Connected my experiences to existing research and reflected on how social media influences my daily life and wellbeing. Breast Cancer Detection ðŸ”— Developed a mammography-based breast cancer detection system utilizing multiple machine learning techniques. Implemented Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Logistic Regression, Neural Networks, and XGBoost for classification. achieved 96.49% accuracy, 100% precision, 92.86% recall, 95.12% F1-score, and 0.996 AUC. Accurate Subtitle Generation in Videos ðŸ”— Developed a system to enhance subtitle accuracy in videos by improving transcription quality, segmentation, and timestamp alignment. Evaluated Whisper variants, LLM-based segmentation (Gemini, SaT), and a custom segmentation function to optimize readability and synchronization. Built a custom dataset with refined SRT files and fine-tuned STT models to better handle accents, long speech, and noisy environments. Implemented a full end-to-end Streamlit pipeline for generating improved subtitles, integrating Whisper transcription, segmentation methods, and FFmpeg-based SRT embedding. ",
  "wordCount" : "421",
  "inLanguage": "en",
  "datePublished": "0001-01-01T00:00:00Z",
  "dateModified": "0001-01-01T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Shizra Tariq"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://shizratariq.github.io/projects/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Shizra Tariq",
    "logo": {
      "@type": "ImageObject",
      "url": "https://shizratariq.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://shizratariq.github.io/" accesskey="h" title="Shizra Tariq (Alt + H)">Shizra Tariq</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://shizratariq.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://shizratariq.github.io/experience/" title="Experience">
                    <span>Experience</span>
                </a>
            </li>
            <li>
                <a href="https://shizratariq.github.io/projects/" title="Projects">
                    <span class="active">Projects</span>
                </a>
            </li>
            <li>
                <a href="https://shizratariq.github.io/skills/" title="Skills">
                    <span>Skills</span>
                </a>
            </li>
            <li>
                <a href="https://shizratariq.github.io/awards/" title="Awards">
                    <span>Awards</span>
                </a>
            </li>
            <li>
                <a href="https://shizratariq.github.io/extracurricular/" title="Extracurricular">
                    <span>Extracurricular</span>
                </a>
            </li>
            <li>
                <a href="https://shizratariq.github.io/cv/" title="CV">
                    <span>CV</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Projects
    </h1>
    <div class="post-meta">2 min&nbsp;Â·&nbsp;Shizra Tariq

</div>
  </header> 
  <div class="post-content">  <div class="two-column-layout" style="display: flex; margin-top: 50px; justify-content: space-between;">
        <div class="text-column" style="flex: 1; justify-contect; margin-right: 50px;">
            <h3 style="font-weight: bold;">
            <a href="/probe/" 
              style="text-decoration: none; color: #B7D8FA; transition: color 0.2s ease;"
              onmouseover="this.style.color='#5555FA';" 
              onmouseout="this.style.color='#B7D8FA';">
              Computer Assisted Nueral Probe Insertion ðŸ”—
            </a>
            </h3>
            <ul style="list-style-type: disc; margin-left: -20px; font-size: 0.9em;">
                <li>Developed a computer-vision pipeline to detect the probe shaft and tip, classify bending, and enable real-time feedback during insertion.</li>
                <li>Curated and labeled datasets, trained segmentation and ResNet models, and analyzed performance issues such as dataset imbalance and visibility challenges.</li>
                <li>Designed and implemented a 3D calibration system using ArUco markers and camera parameters to convert 2D detections into accurate 3D insertion coordinates.</li>
                <li>Built the workflow for automated probe insertion, including insertion-point estimation, reference-frame creation, trajectory planning for robotic control./li>
            </ul>
        </div>
        <div class="video-column" style="flex: 1; margin-top: 30px">
            <a href="/probe/">
                <img src= https://github.com/user-attachments/assets/07e8e5ef-b80e-49d2-8773-8c01d5438507 alt="Video Thumbnail" style="width: 100%; cursor: pointer;">
            </a>
        </div>
</div>
<hr>
  <div class="two-column-layout" style="display: flex; margin-top: 50px; justify-content: space-between;">
        <div class="text-column" style="flex: 1; justify-contect; margin-right: 50px;">
            <h3 style="font-weight: bold;">
            <a href="https://github.com/shizratariq/Turtlebot3-RRT-Pathfinder" 
              style="text-decoration: none; color: #B7D8FA; transition: color 0.2s ease;"
              onmouseover="this.style.color='#5555FA';" 
              onmouseout="this.style.color='#B7D8FA';">
              Turtlebot3 RRT Pathfinder ðŸ”—
            </a>
            </h3>
            <ul style="list-style-type: disc; margin-left: -20px; font-size: 0.9em;">
                <li>Developed and implemented the Rapidly-Exploring Random Tree (RRT) algorithm for autonomous maze navigation in Gazebo simulations.</li>
                <li>Optimized motor command accuracy to enhance path-following precision.</li>
                <li>Addressed Lidar inconsistencies by refining sensor data processing for improved obstacle detection.</li>
                <li>Achieved a 40% success rate in maze traversal under simulated conditions.</li>
                <li>Recorded a fastest traversal time of 1 minute and 42 seconds.</li>
                <li>Improved overall navigation efficiency through iterative testing and parameter tuning. </li>
            </ul>
        </div>
        <div class="video-column" style="flex: 1; margin-top: 30px">
            <a href="https://github.com/shizratariq/Turtlebot3-RRT-Pathfinder" target="_blank">
                <img src= https://github.com/user-attachments/assets/a241002d-1e30-4e9d-ac42-8e8d7268ba81 alt="Video Thumbnail" style="width: 100%; cursor: pointer;">
            </a>
        </div>
</div>
<hr>
  <div class="two-column-layout" style="display: flex; margin-top: 50px; justify-content: space-between;">
        <div class="text-column" style="flex: 1; justify-contect; margin-right: 50px;">
            <h3 style="font-weight: bold;">
            <a href="/super_resol/" 
              style="text-decoration: none; color: #B7D8FA; transition: color 0.2s ease;"
              onmouseover="this.style.color='#5555FA';" 
              onmouseout="this.style.color='#B7D8FA';">
              SuperResolution and Object Detection on Remote Sensing Imagery ðŸ”—
            </a>
            </h3>
            <ul style="list-style-type: disc; margin-left: -20px; font-size: 0.9em;">
                <li>Implemented <strong>SRGAN (4x super-resolution)</strong> to enhance image quality.</li>
                <li>Improved <strong>Peak Signal-to-Noise Ratio (PSNR)</strong> and <strong>Structural Similarity Index (SSIM)</strong> metrics.</li>
                <li>Achieved a <strong>+18.7% increase in mean Average Precision (mAP)</strong> for aerial object detection.</li>
                <li>Boosted mAP from <strong>49.6% to 68.3%</strong> using enhanced images.</li>
                <li>Utilized <strong>YOLOv11-OBB</strong> for detecting <strong>8 object classes</strong> in the <strong>DOTA dataset</strong>.</li>
                <li>Enhanced object detection accuracy by improving input image resolution.</li>
        </div>
        <div class="video-column" style="flex: 1; margin-top: 30px">
            <a href="/super_resol/" target="_blank">
                <img src= https://github.com/user-attachments/assets/cfb2e808-574e-4ed2-8ac2-62b2c98a1d27 alt="Video Thumbnail" style="width: 100%; cursor: pointer;">
            </a>
        </div>
</div>
<hr>
  <div class="two-column-layout" style="display: flex; margin-top: 50px; justify-content: space-between;">
        <div class="text-column" style="flex: 1; justify-contect; margin-right: 50px;">
            <h3 style="font-weight: bold;">
            <a href="/auto/" 
              style="text-decoration: none; color: #B7D8FA; transition: color 0.2s ease;"
              onmouseover="this.style.color='#5555FA';" 
              onmouseout="this.style.color='#B7D8FA';">
              Autoethnographic Study on Social Media Usage ðŸ”—
            </a>
            </h3>
            <ul style="list-style-type: disc; margin-left: -20px; font-size: 0.9em;">
                <li>Collected two weeks of data on my social media use through field notes, journal entries, and reflections.</li>
                <li>Examined how my cultural background and personal habits shape the way I use different social apps.</li>
                <li>Identified key themes such as emotional impact, productivity vs. distraction, and platform-specific behaviors.</li>
                <li>Connected my experiences to existing research and reflected on how social media influences my daily life and wellbeing.</li>
            </ul>
        </div>
        <div class="video-column" style="flex: 1; margin-top: 30px">
            <a href="/auto/" target="_blank">
                <img src= https://github.com/user-attachments/assets/d391b6c6-737d-4968-81ec-1e57733d8a47 alt="Video Thumbnail" style="width: 100%; cursor: pointer;">
            </a>
        </div>
</div>
<hr>
  <div class="two-column-layout" style="display: flex; margin-top: 50px; justify-content: space-between;">
        <div class="text-column" style="flex: 1; justify-contect; margin-right: 50px;">
            <h3 style="font-weight: bold;">
            <a href="/breast_cancer/" 
              style="text-decoration: none; color: #B7D8FA; transition: color 0.2s ease;"
              onmouseover="this.style.color='#5555FA';" 
              onmouseout="this.style.color='#B7D8FA';">
              Breast Cancer Detection ðŸ”—
            </a>
            </h3>
            <ul style="list-style-type: disc; margin-left: -20px; font-size: 0.9em;">
                <li>Developed a mammography-based breast cancer detection system utilizing multiple machine learning techniques.</li>
                <li>Implemented Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Logistic Regression, Neural Networks, and XGBoost for classification.</li>
                <li>achieved 96.49% accuracy, 100% precision, 92.86% recall, 95.12% F1-score, and 0.996 AUC.</li>
        </div>
        <div class="video-column" style="flex: 1; margin-top: 30px">
            <a href="/breast_cancer/"  target="_blank">
                <img src= https://github.com/user-attachments/assets/965ce6ab-afae-48f5-917c-4b4acd009897 alt="Video Thumbnail" style="width: 100%; cursor: pointer;">
            </a>
        </div>
</div>
<hr>
  <div class="two-column-layout" style="display: flex; margin-top: 50px; justify-content: space-between;">
        <div class="text-column" style="flex: 1; justify-contect; margin-right: 50px;">
            <h3 style="font-weight: bold;">
            <a href="/subtitle/" 
              style="text-decoration: none; color: #B7D8FA; transition: color 0.2s ease;"
              onmouseover="this.style.color='#5555FA';" 
              onmouseout="this.style.color='#B7D8FA';">
              Accurate Subtitle Generation in Videos ðŸ”—
            </a>
            </h3>
            <ul style="list-style-type: disc; margin-left: -20px; font-size: 0.9em;">
                <li>Developed a system to enhance subtitle accuracy in videos by improving transcription quality, segmentation, and timestamp alignment.</li>
                <li>Evaluated Whisper variants, LLM-based segmentation (Gemini, SaT), and a custom segmentation function to optimize readability and synchronization.</li>
                <li>Built a custom dataset with refined SRT files and fine-tuned STT models to better handle accents, long speech, and noisy environments.</li>
                <li>Implemented a full end-to-end Streamlit pipeline for generating improved subtitles, integrating Whisper transcription, segmentation methods, and FFmpeg-based SRT embedding.</li>
        </div>
        <div class="video-column" style="flex: 1; margin-top: 30px">
            <a href="/subtitle/" target="_blank">
                <img src= https://github.com/user-attachments/assets/1f43871e-df3a-4946-a2b9-22edc3fd0c6c alt="Video Thumbnail" style="width: 100%; cursor: pointer;">
            </a>
        </div>
</div>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://shizratariq.github.io/">Shizra Tariq</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
